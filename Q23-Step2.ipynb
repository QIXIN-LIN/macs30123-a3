{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 & Q3 - Step2 (run on Spark EMR cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1715914439535_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-20-37.ec2.internal:20888/proxy/application_1715914439535_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-16-175.ec2.internal:8042/node/containerlogs/container_1715914439535_0003_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python3', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv'}, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1715914439535_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-20-37.ec2.internal:20888/proxy/application_1715914439535_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-16-175.ec2.internal:8042/node/containerlogs/container_1715914439535_0003_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.pyspark.python\": \"python3\",\n",
    "        \"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "        \"spark.pyspark.virtualenv.type\":\"native\",\n",
    "        \"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.0.5\n",
      "  Using cached https://files.pythonhosted.org/packages/af/f3/683bf2547a3eaeec15b39cef86f61e921b3b187f250fcd2b5c5fb4386369/pandas-1.0.5-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib64/python3.7/site-packages (from pandas==1.0.5)\n",
      "Collecting python-dateutil>=2.6.1 (from pandas==1.0.5)\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.0.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas==1.0.5)\n",
      "Installing collected packages: python-dateutil, pandas\n",
      "Successfully installed pandas-1.0.5 python-dateutil-2.9.0.post0\n",
      "\n",
      "Collecting scipy==1.4.1\n",
      "  Using cached https://files.pythonhosted.org/packages/dd/82/c1fe128f3526b128cfd185580ba40d01371c5d299fcf7f77968e22dfcc2e/scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib64/python3.7/site-packages (from scipy==1.4.1)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.4.1\n",
      "\n",
      "Collecting matplotlib==3.2.1\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/c2/71fcf957710f3ba1f09088b35776a799ba7dd95f7c2b195ec800933b276b/matplotlib-3.2.1-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib==3.2.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/ea/6d76df31432a0e6fdf81681a895f009a4bb47b3c39036db3e1b528191d52/pyparsing-3.1.2-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /mnt/tmp/1715917468195-0/lib/python3.7/site-packages (from matplotlib==3.2.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib64/python3.7/site-packages (from matplotlib==3.2.1)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.2.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/5c/f9/695d6bedebd747e5eb0fe8fad57b72fdf25411273a39791cde838d5a8f51/cycler-0.11.0-py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib==3.2.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/f9/77/e3046bf19720b22e3e0b7c12e28f6f2c0c18a213fb91a56cea640862270f/kiwisolver-1.4.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib==3.2.1)\n",
      "Collecting typing-extensions; python_version < \"3.8\" (from kiwisolver>=1.0.1->matplotlib==3.2.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl\n",
      "Installing collected packages: pyparsing, cycler, typing-extensions, kiwisolver, matplotlib\n",
      "Successfully installed cycler-0.11.0 kiwisolver-1.4.5 matplotlib-3.2.1 pyparsing-3.1.2 typing-extensions-4.7.1"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"pandas==1.0.5\", \"https://pypi.org/simple\")\n",
    "sc.install_pypi_package(\"scipy==1.4.1\", \"https://pypi.org/simple\")\n",
    "sc.install_pypi_package(\"matplotlib==3.2.1\", \"https://pypi.org/simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, Bucketizer\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import dayofweek\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the parquet file\n",
    "data = spark.read.parquet('s3://nyc-tlc/trip data/yellow_tripdata_2015*.parquet')\n",
    "\n",
    "# Clean the dataset\n",
    "data = data.filter(col('tip_amount') >= 0)\n",
    "data = data.filter(col('tip_amount') < 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Q2a - Engineer Additional Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature1 - Weekend\n",
    "\n",
    "This is the feature in the existing linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add day_of_week and weekend features\n",
    "data = data.withColumn('day_of_week', F.dayofweek(F.col('tpep_pickup_datetime'))) \\\n",
    "           .withColumn('weekend', F.col('day_of_week').isin({7, 1}).cast('integer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature2 - Hour of Day (date/time feature, one-hot encoded)\n",
    "\n",
    "Add \"Hour of Day\" to the model because we observed in Q1's visualization that it influences the tip amount. Specifically, people tend to tip more around 5am and 7pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add hour_of_day feature\n",
    "data = data.withColumn('hour_of_day', F.hour(data.tpep_pickup_datetime))\n",
    "\n",
    "# Index the hour_of_day\n",
    "hour_indexer = StringIndexer(inputCol=\"hour_of_day\", outputCol=\"hour_of_day_index\").fit(data)\n",
    "data = hour_indexer.transform(data)\n",
    "\n",
    "# One-hot encode the indexed hour_of_day\n",
    "hour_encoder = OneHotEncoder(inputCol=\"hour_of_day_index\", outputCol=\"hour_of_day_vector\")\n",
    "hour_encoder_model = hour_encoder.fit(data)\n",
    "data = hour_encoder_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the order of one-hot encoding index and the baseline category of hour_of_day feature\n",
    "\n",
    "# Collect the frequencies into a list and sort by count in descending order\n",
    "frequency_df = data.groupBy('hour_of_day').count()\n",
    "frequencies = frequency_df.orderBy(col('count').desc()).collect()\n",
    "\n",
    "# Get ordered list of feature category based on the frequencies\n",
    "hour_to_index = {row['hour_of_day']: idx for idx, row in enumerate(frequencies)}\n",
    "sorted_hours = sorted(hour_to_index.items(), key=lambda item: item[1])\n",
    "hour_features = [f\"hour_of_day_{hour}\" for hour, _ in sorted_hours]\n",
    "\n",
    "# Remove the baseline category and store it in a variable\n",
    "hour_baseline = hour_features.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature3 - Day of Week (categorical feature, one-hot encoded) \n",
    "\n",
    "Add \"Day of Week\" to the model because we observed in Q1's visualization that it influences the tip amount. Specifically, people tip more during the weekdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# StringIndexer for day_of_week\n",
    "indexer = StringIndexer(inputCol='day_of_week', outputCol='day_of_week_index')\n",
    "data = indexer.fit(data).transform(data)\n",
    "\n",
    "# OneHotEncoder for day_of_week_index\n",
    "encoder = OneHotEncoder(inputCol='day_of_week_index', outputCol='day_of_week_vector')\n",
    "data = encoder.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the order of one-hot encoding index and the baseline category of day_of_week feature\n",
    "\n",
    "# Calculate the frequency of each day_of_week and sort by count in descending order\n",
    "frequency_df = data.groupBy('day_of_week').count()\n",
    "frequencies = frequency_df.orderBy(col('count').desc()).collect()\n",
    "\n",
    "# Get ordered list of feature category based on the frequencies\n",
    "day_to_index = {row['day_of_week']: idx for idx, row in enumerate(frequencies)}\n",
    "sorted_days = sorted(day_to_index.items(), key=lambda item: item[1])\n",
    "day_features = [f\"day_of_week_{day}\" for day, _ in sorted_days]\n",
    "\n",
    "# Remove the baseline category and store it in a variable\n",
    "day_baseline = day_features.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature4 - Passenger Count (integer feature, bucketized and one-hot encoded)\n",
    "\n",
    "Add \"Passenger Count\" to the model because we observed in Q1's visualization that it influences the tip amount. Specifically, larger groups of people (more than 6) tend to tip more significantly. However, note that this is a driver-entered value, and there are many entries with 0, possibly because drivers don't always bother to enter the passenger count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the splits for passenger_count buckets\n",
    "passenger_splits = [-float('inf'), 1.0, 2.0, 5.0, float('inf')]\n",
    "\n",
    "# Initialize the Bucketizer for passenger_count\n",
    "passenger_bucketizer = Bucketizer(splits=passenger_splits, inputCol=\"passenger_count\", outputCol=\"passenger_count_bucket\")\n",
    "\n",
    "# Transform the data for passenger_count buckets\n",
    "data = passenger_bucketizer.setHandleInvalid(\"skip\").transform(data)\n",
    "\n",
    "# Index the passenger_count_bucket\n",
    "passenger_count_indexer = StringIndexer(inputCol=\"passenger_count_bucket\", outputCol=\"passenger_count_index\").fit(data)\n",
    "data = passenger_count_indexer.transform(data)\n",
    "\n",
    "# One-hot encode the indexed passenger_count_bucket\n",
    "passenger_count_encoder = OneHotEncoder(inputCol=\"passenger_count_index\", outputCol=\"passenger_count_vector\")\n",
    "passenger_count_encoder_model = passenger_count_encoder.fit(data)\n",
    "data = passenger_count_encoder_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+\n",
      "|passenger_count|    count|\n",
      "+---------------+---------+\n",
      "|              5|  7937313|\n",
      "|              6|  5123157|\n",
      "|              9|      165|\n",
      "|              1|102928494|\n",
      "|              3|  6133758|\n",
      "|              2| 20893560|\n",
      "|              0|    40681|\n",
      "|              7|      227|\n",
      "|              8|      178|\n",
      "|              4|  2980689|\n",
      "+---------------+---------+\n",
      "\n",
      "+----------------------+---------+\n",
      "|passenger_count_vector|    count|\n",
      "+----------------------+---------+\n",
      "|         (3,[2],[1.0])| 13061040|\n",
      "|         (3,[1],[1.0])| 30008007|\n",
      "|         (3,[0],[1.0])|102928494|\n",
      "|             (3,[],[])|    40681|\n",
      "+----------------------+---------+"
     ]
    }
   ],
   "source": [
    "# Show the distribution\n",
    "distribution = data.groupBy('passenger_count').count()\n",
    "distribution.show()\n",
    "\n",
    "# Show the vector distribution to clarify the order of one-hot encoding features\n",
    "distribution = data.groupBy('passenger_count_vector').count()\n",
    "distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the order of one-hot encoding features and the baseline category based on the distribution\n",
    "# Because it has change the order of index during the bucketization\n",
    "\n",
    "passenger_count_features = [\"passenger_count_1\", \"passenger_count_2_4\", \"passenger_count_5_\", \"passenger_count_NA\"]\n",
    "\n",
    "# Remove the baseline category and store it in a variable\n",
    "passenger_count_baseline = passenger_count_features.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature5 - Borough to Pickup (spatial feature, one-hot encoded)\n",
    "\n",
    "Add \"Borough to Pickup\" in the model to reflect the potential variability in tipping habits or travel purposes among passengers originating from different boroughs, which could impact the tip amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n",
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Get the csv file from s3 bucket\n",
    "zone_lookup_path = 's3://qixin-a3-bucket/jupyter/jovyan/taxi_zone_lookup.csv'\n",
    "zone_lookup = spark.read.option(\"header\", \"true\").csv(zone_lookup_path)\n",
    "\n",
    "# Show the schema and a few rows of the lookup data\n",
    "zone_lookup.printSchema()\n",
    "zone_lookup.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add the PUBorough feature to the dataset\n",
    "zone_lookup = zone_lookup.withColumnRenamed(\"LocationID\", \"PULocationID\").withColumnRenamed(\"Borough\", \"PUBorough\")\n",
    "data = data.join(zone_lookup, on=\"PULocationID\", how=\"left\")\n",
    "\n",
    "# Add the DOBorough feature to the dataset\n",
    "zone_lookup = zone_lookup.withColumnRenamed(\"PULocationID\", \"DOLocationID\").withColumnRenamed(\"PUBorough\", \"DOBorough\")\n",
    "data = data.join(zone_lookup, on=\"DOLocationID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Index and one-hot encode the PUBorough\n",
    "pu_borough_indexer = StringIndexer(inputCol=\"PUBorough\", outputCol=\"PUBorough_index\").fit(data)\n",
    "data = pu_borough_indexer.transform(data)\n",
    "pu_borough_encoder = OneHotEncoder(inputCol=\"PUBorough_index\", outputCol=\"PUBorough_vector\")\n",
    "pu_borough_encoder_model = pu_borough_encoder.fit(data)\n",
    "data = pu_borough_encoder_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the order of one-hot encoding index \n",
    "\n",
    "# Collect the frequencies into a list and sort by count in descending order\n",
    "frequency_df = data.groupBy('PUBorough').count()\n",
    "frequencies = frequency_df.orderBy(col('count').desc()).collect()\n",
    "\n",
    "# Get ordered list of feature category based on the frequencies\n",
    "PUBorough_to_index = {row['PUBorough']: idx for idx, row in enumerate(frequencies)}\n",
    "sorted_PUBorough = sorted(PUBorough_to_index.items(), key=lambda item: item[1])\n",
    "PUBorough_features = [f\"PUBorough_{Borough}\" for Borough, _ in sorted_PUBorough]\n",
    "\n",
    "# Remove the baseline category and store it in a variable\n",
    "PUBorough_baseline = PUBorough_features.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature6 - Trip Distance (floating point feature) & Feature7 - Fare Amount (floating point feature)\n",
    "\n",
    "Add \"Trip Distance\" to the model because people might give more tips on long-distance trips due to increased fare amounts or longer travel times.\n",
    "\n",
    "Add \"Fare Amount\" to the model because people might give more tips when the fare amount is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2a - Build Linear Regression Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|tip_amount|            features|\n",
      "+----------+--------------------+\n",
      "|       1.4|(42,[1,2,3,22,31,...|\n",
      "|       0.0|(42,[1,2,3,22,31,...|\n",
      "|       2.9|(42,[1,2,3,22,31,...|\n",
      "|      2.37|(42,[1,2,3,22,31,...|\n",
      "|       0.0|(42,[1,2,3,22,31,...|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "#data = data.drop('features')  #Remove the existing 'features' column if there's one before\n",
    "\n",
    "features = ['weekend', 'trip_distance',  'fare_amount', 'passenger_count_vector', 'hour_of_day_vector', 'day_of_week_vector', 'PUBorough_vector']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "\n",
    "data = assembler.transform(data)\n",
    "data[['tip_amount', 'features']].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True"
     ]
    }
   ],
   "source": [
    "# Use a subset of data for trial - prepare to run the full dataset in the pipeline\n",
    "\n",
    "sampled_data = data.sample(fraction=0.001, seed=42)\n",
    "train, test = sampled_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Persist data in memory to speed up I/O during training/testing\n",
    "train.persist()\n",
    "test.persist()\n",
    "\n",
    "# confirm they're cached\n",
    "print(train.is_cached, test.is_cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [4.360983518826533,0.1770216631997958,0.06835356323241612,0.7971570878457249,0.67371430857873,0.7765339425756856,0.286785174329209,0.24808160327506928,0.2762210079117851,0.2443631730995019,0.2805118149078387,0.09274658798445717,0.15660175749607408,0.16076066186226132,0.12151273255705293,0.22901747132162056,0.11137339169389483,0.12848346201503935,0.19536933309429008,0.12835382048850996,0.23617532585193213,0.13696056303973525,0.18155044088149902,0.17297574220734027,0.13061393649648717,0.052309848045051476,0.07238224965818747,-0.06263907810482393,-0.15908296072249628,-4.501480609860989,0.03291189629744201,0.06613546044265059,0.07094999360923764,0.07120477971190783,-4.471068859894281,0.7500198810103271,0.6931163943324465,0.7782816415996743,0.8450668967407127,0.7323505393570933,2.3062560008422976,13.196164410992406]\n",
      "Intercept: -1.4103424961522115"
     ]
    }
   ],
   "source": [
    "# Create a Linear Regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"tip_amount\")\n",
    "\n",
    "# Fit the model to the training data\n",
    "lr_model = lr.fit(train)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(f\"Coefficients: {lr_model.coefficients}\")\n",
    "print(f'Intercept: {lr_model.intercept}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.9679645393447491"
     ]
    }
   ],
   "source": [
    "# Evaluate with test data using `evaluate` method\n",
    "lr_evaluation_summary = lr_model.evaluate(test)\n",
    "\n",
    "# Print out evaluation metrics like RMSE:\n",
    "print(f'Test RMSE: {lr_evaluation_summary.rootMeanSquaredError}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_baseline: day_of_week_2\n",
      "hour_baseline: hour_of_day_5\n",
      "PUBorough_baseline: PUBorough_Staten Island\n",
      "passenger_count_baseline: passenger_count_NA\n",
      "                Feature  Coefficient\n",
      "41        PUBorough_EWR    13.196164\n",
      "29        day_of_week_7    -4.501481\n",
      "34        day_of_week_1    -4.471069\n",
      "0               weekend     4.360984\n",
      "40        PUBorough_N/A     2.306256\n",
      "38    PUBorough_Unknown     0.845067\n",
      "3     passenger_count_1     0.797157\n",
      "37   PUBorough_Brooklyn     0.778282\n",
      "5    passenger_count_5_     0.776534\n",
      "35  PUBorough_Manhattan     0.750020\n",
      "39      PUBorough_Bronx     0.732351\n",
      "36     PUBorough_Queens     0.693116\n",
      "4   passenger_count_2_4     0.673714\n",
      "6        hour_of_day_19     0.286785\n",
      "10       hour_of_day_22     0.280512\n",
      "8        hour_of_day_20     0.276221\n",
      "7        hour_of_day_18     0.248082\n",
      "9        hour_of_day_21     0.244363\n",
      "20        hour_of_day_8     0.236175\n",
      "15       hour_of_day_23     0.229017\n",
      "18        hour_of_day_9     0.195369\n",
      "22        hour_of_day_0     0.181550\n",
      "1         trip_distance     0.177022\n",
      "23        hour_of_day_7     0.172976\n",
      "13       hour_of_day_12     0.160761\n",
      "28        hour_of_day_4    -0.159083\n",
      "12       hour_of_day_17     0.156602\n",
      "21       hour_of_day_16     0.136961\n",
      "24        hour_of_day_1     0.130614\n",
      "17       hour_of_day_11     0.128483\n",
      "19       hour_of_day_10     0.128354\n",
      "14       hour_of_day_13     0.121513\n",
      "16       hour_of_day_15     0.111373\n",
      "11       hour_of_day_14     0.092747\n",
      "26        hour_of_day_2     0.072382\n",
      "33        day_of_week_3     0.071205\n",
      "32        day_of_week_4     0.070950\n",
      "2           fare_amount     0.068354\n",
      "31        day_of_week_5     0.066135\n",
      "27        hour_of_day_3    -0.062639\n",
      "25        hour_of_day_6     0.052310\n",
      "30        day_of_week_6     0.032912"
     ]
    }
   ],
   "source": [
    "# Extract the coefficients and feature names\n",
    "coefficients = lr_model.coefficients\n",
    "feature_names = ['weekend', 'trip_distance', 'fare_amount'] + \\\n",
    "                  passenger_count_features + \\\n",
    "                  hour_features + \\\n",
    "                  day_features + \\\n",
    "                  PUBorough_features\n",
    "\n",
    "# Display the baseline category for one-hot encoded features\n",
    "baselines = {\n",
    "    \"day_baseline\": day_baseline,\n",
    "    \"hour_baseline\": hour_baseline,\n",
    "    \"PUBorough_baseline\": PUBorough_baseline,\n",
    "    \"passenger_count_baseline\": passenger_count_baseline\n",
    "}\n",
    "for name, value in baselines.items():\n",
    "    print(f\"{name}: {value}\")\n",
    "\n",
    "# Display feature importance in descending order (of absolute value)\n",
    "feature_importance = pd.DataFrame(list(zip(feature_names, coefficients)), columns=[\"Feature\", \"Coefficient\"])\n",
    "feature_importance_sorted = feature_importance.reindex(feature_importance.Coefficient.abs().sort_values(ascending=False).index)\n",
    "print(feature_importance_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2b - Organize All Transformers and Estimators into a Reproducible Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Bucketizer, StringIndexer, OneHotEncoder, VectorAssembler, SQLTransformer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Clean the dataset\n",
    "data = spark.read.parquet('s3://nyc-tlc/trip data/yellow_tripdata_2015*.parquet')\n",
    "data = data.filter(col('tip_amount') >= 0)\n",
    "data = data.filter(col('tip_amount') < 2000)\n",
    "\n",
    "# Get Borough features from csv file\n",
    "zone_lookup_path = \"s3://qixin-a3-bucket/jupyter/jovyan/taxi_zone_lookup.csv\"\n",
    "zone_lookup = spark.read.option(\"header\", \"true\").csv(zone_lookup_path)\n",
    "zone_lookup = zone_lookup.withColumnRenamed(\"LocationID\", \"PULocationID\").withColumnRenamed(\"Borough\", \"PUBorough\")\n",
    "data = data.join(zone_lookup, on=\"PULocationID\", how=\"left\")\n",
    "zone_lookup = zone_lookup.withColumnRenamed(\"PULocationID\", \"DOLocationID\").withColumnRenamed(\"PUBorough\", \"DOBorough\")\n",
    "data = data.join(zone_lookup, on=\"DOLocationID\", how=\"left\")\n",
    "\n",
    "# Define the transformations as stages in the pipeline\n",
    "stages = []\n",
    "\n",
    "# Use SQLTransformer to add day_of_week and weekend features\n",
    "sql_transformer = SQLTransformer(statement=\"\"\"\n",
    "    SELECT *,\n",
    "           dayofweek(tpep_pickup_datetime) AS day_of_week,\n",
    "           CASE WHEN dayofweek(tpep_pickup_datetime) IN (1, 7) THEN 1 ELSE 0 END AS weekend\n",
    "    FROM __THIS__\n",
    "\"\"\")\n",
    "stages += [sql_transformer]\n",
    "\n",
    "# Index and one-hot encode the PUBorough\n",
    "pu_borough_indexer = StringIndexer(inputCol=\"PUBorough\", outputCol=\"PUBorough_index\")\n",
    "pu_borough_encoder = OneHotEncoder(inputCol=\"PUBorough_index\", outputCol=\"PUBorough_vector\")\n",
    "stages += [pu_borough_indexer, pu_borough_encoder]\n",
    "\n",
    "# Extract, index and one-hot encode the hour_of_day\n",
    "data = data.withColumn('hour_of_day', F.hour(data.tpep_pickup_datetime))\n",
    "hour_indexer = StringIndexer(inputCol=\"hour_of_day\", outputCol=\"hour_of_day_index\")\n",
    "hour_encoder = OneHotEncoder(inputCol=\"hour_of_day_index\", outputCol=\"hour_of_day_vector\")\n",
    "stages += [hour_indexer, hour_encoder]\n",
    "\n",
    "# Index and one-hot encode the day_of_week\n",
    "day_indexer = StringIndexer(inputCol=\"day_of_week\", outputCol=\"day_of_week_index\")\n",
    "day_encoder = OneHotEncoder(inputCol=\"day_of_week_index\", outputCol=\"day_of_week_vector\")\n",
    "stages += [day_indexer, day_encoder]\n",
    "\n",
    "# Buckeize the passenger_count\n",
    "passenger_splits = [-float('inf'), 1.0, 2.0, 5.0, float('inf')]\n",
    "passenger_bucketizer = Bucketizer(splits=passenger_splits, inputCol=\"passenger_count\", outputCol=\"passenger_count_bucket\")\n",
    "stages += [passenger_bucketizer]\n",
    "\n",
    "# Index and one-hot encode the passenger_count_bucket\n",
    "passenger_count_indexer = StringIndexer(inputCol=\"passenger_count_bucket\", outputCol=\"passenger_count_index\")\n",
    "passenger_count_encoder = OneHotEncoder(inputCol=\"passenger_count_index\", outputCol=\"passenger_count_vector\")\n",
    "stages += [passenger_count_indexer, passenger_count_encoder]\n",
    "\n",
    "# Assemble the feature columns into a single feature vector\n",
    "feature_columns = [\n",
    "    \"weekend\",\n",
    "    \"trip_distance\",\n",
    "    \"fare_amount\",\n",
    "    \"passenger_count_vector\",\n",
    "    \"hour_of_day_vector\",\n",
    "    \"day_of_week_vector\",\n",
    "    \"PUBorough_vector\",\n",
    "]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "\n",
    "# Create a Linear Regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"tip_amount\")\n",
    "stages += [lr]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True"
     ]
    }
   ],
   "source": [
    "# Start with the subset of data - it should get the same outcome with Q2a\n",
    "sampled_data = data.sample(fraction=0.001, seed=42)\n",
    "train, test = sampled_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Persist data in memory to speed up I/O during training/testing\n",
    "train.persist()\n",
    "test.persist()\n",
    "\n",
    "# confirm they're cached\n",
    "print(train.is_cached, test.is_cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+--------------------------------------------------------+\n",
      "|prediction        |tip_amount|features                                                |\n",
      "+------------------+----------+--------------------------------------------------------+\n",
      "|12.941511103766606|0.0       |(42,[2,3,15,31,41],[2.5,1.0,1.0,1.0,1.0])               |\n",
      "|7.103404608040409 |10.8      |(42,[0,1,2,3,16,34,35],[1.0,15.6,61.5,1.0,1.0,1.0,1.0]) |\n",
      "|8.41971505496696  |17.65     |(42,[0,1,2,5,14,29,35],[1.0,19.57,70.5,1.0,1.0,1.0,1.0])|\n",
      "|8.126635576798902 |16.0      |(42,[1,2,4,16,31,35],[17.8,70.0,1.0,1.0,1.0,1.0])       |\n",
      "|9.072528579155577 |18.0      |(42,[1,2,3,20,35],[20.6,75.5,1.0,1.0,1.0])              |\n",
      "+------------------+----------+--------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data: 1.9679645393447491"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to the training data and make predictions on the test data\n",
    "pipeline_model = pipeline.fit(train)\n",
    "predictions = pipeline_model.transform(test)\n",
    "\n",
    "# Show the predictions\n",
    "predictions.select(\"prediction\", \"tip_amount\", \"features\").show(5, truncate=False)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"tip_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_baseline: day_of_week_2\n",
      "hour_baseline: hour_of_day_5\n",
      "PUBorough_baseline: PUBorough_Staten Island\n",
      "passenger_count_baseline: passenger_count_NA\n",
      "                Feature  Coefficient\n",
      "41        PUBorough_EWR    13.196164\n",
      "29        day_of_week_7    -4.343046\n",
      "34        day_of_week_1    -4.312634\n",
      "0               weekend     4.202549\n",
      "40        PUBorough_N/A     2.306256\n",
      "38    PUBorough_Unknown     0.845067\n",
      "3     passenger_count_1     0.797157\n",
      "37   PUBorough_Brooklyn     0.778282\n",
      "5    passenger_count_5_     0.776534\n",
      "35  PUBorough_Manhattan     0.750020\n",
      "39      PUBorough_Bronx     0.732351\n",
      "36     PUBorough_Queens     0.693116\n",
      "4   passenger_count_2_4     0.673714\n",
      "6        hour_of_day_19     0.286785\n",
      "10       hour_of_day_22     0.280512\n",
      "8        hour_of_day_20     0.276221\n",
      "7        hour_of_day_18     0.248082\n",
      "9        hour_of_day_21     0.244363\n",
      "19       hour_of_day_10     0.236175\n",
      "13       hour_of_day_12     0.229017\n",
      "18        hour_of_day_9     0.195369\n",
      "22        hour_of_day_0     0.181550\n",
      "1         trip_distance     0.177022\n",
      "23        hour_of_day_7     0.172976\n",
      "14       hour_of_day_13     0.160761\n",
      "28        hour_of_day_4    -0.159083\n",
      "12       hour_of_day_17     0.156602\n",
      "21       hour_of_day_16     0.136961\n",
      "24        hour_of_day_1     0.130614\n",
      "17       hour_of_day_11     0.128483\n",
      "20        hour_of_day_8     0.128354\n",
      "15       hour_of_day_23     0.121513\n",
      "16       hour_of_day_15     0.111373\n",
      "11       hour_of_day_14     0.092747\n",
      "26        hour_of_day_2     0.072382\n",
      "33        day_of_week_3     0.071205\n",
      "32        day_of_week_4     0.070950\n",
      "2           fare_amount     0.068354\n",
      "31        day_of_week_5     0.066135\n",
      "27        hour_of_day_3    -0.062639\n",
      "25        hour_of_day_6     0.052310\n",
      "30        day_of_week_6     0.032912"
     ]
    }
   ],
   "source": [
    "# Extract the coefficients and feature names\n",
    "linear_model = pipeline_model.stages[-1]\n",
    "coefficients = linear_model.coefficients\n",
    "feature_names = ['weekend', 'trip_distance', 'fare_amount'] + \\\n",
    "                  passenger_count_features + \\\n",
    "                  hour_features + \\\n",
    "                  day_features + \\\n",
    "                  PUBorough_features\n",
    "\n",
    "# Display the baseline category for one-hot encoded features\n",
    "baselines = {\n",
    "    \"day_baseline\": day_baseline,\n",
    "    \"hour_baseline\": hour_baseline,\n",
    "    \"PUBorough_baseline\": PUBorough_baseline,\n",
    "    \"passenger_count_baseline\": passenger_count_baseline\n",
    "}\n",
    "for name, value in baselines.items():\n",
    "    print(f\"{name}: {value}\")\n",
    "\n",
    "# Display feature importance in descending order (of absolute value)\n",
    "feature_importance = pd.DataFrame(list(zip(feature_names, coefficients)), columns=[\"Feature\", \"Coefficient\"])\n",
    "feature_importance_sorted = feature_importance.reindex(feature_importance.Coefficient.abs().sort_values(ascending=False).index)\n",
    "print(feature_importance_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True"
     ]
    }
   ],
   "source": [
    "# Scale training data up to the full dataset\n",
    "full_data = data\n",
    "train, test = full_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Persist data in memory to speed up I/O during training/testing\n",
    "train.persist()\n",
    "test.persist()\n",
    "\n",
    "# confirm they're cached\n",
    "print(train.is_cached, test.is_cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+------------------------------------------------+\n",
      "|prediction        |tip_amount|features                                        |\n",
      "+------------------+----------+------------------------------------------------+\n",
      "|10.180062794762545|0.0       |(42,[2,4,23,31,41],[82.0,1.0,1.0,1.0,1.0])      |\n",
      "|10.18504640529684 |0.0       |(42,[2,3,14,31,41],[0.01,1.0,1.0,1.0,1.0])      |\n",
      "|10.187047172271036|0.0       |(42,[2,3,14,31,41],[2.5,1.0,1.0,1.0,1.0])       |\n",
      "|10.219750325470214|5.0       |(42,[1,2,4,16,31,41],[6.3,82.0,1.0,1.0,1.0,1.0])|\n",
      "|10.22361105954122 |0.0       |(42,[2,4,7,31,41],[75.0,1.0,1.0,1.0,1.0])       |\n",
      "+------------------+----------+------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data: 2.5143160191883713"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to the training data of full dataset and make predictions on the test data\n",
    "pipeline_model = pipeline.fit(train)\n",
    "predictions = pipeline_model.transform(test)\n",
    "\n",
    "# Show the predictions\n",
    "predictions.select(\"prediction\", \"tip_amount\", \"features\").show(5, truncate=False)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"tip_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_baseline: day_of_week_2\n",
      "hour_baseline: hour_of_day_5\n",
      "PUBorough_baseline: PUBorough_Staten Island\n",
      "passenger_count_baseline: passenger_count_NA\n",
      "                Feature   Coefficient\n",
      "39      PUBorough_Bronx -5.105274e+00\n",
      "35  PUBorough_Manhattan -4.670595e+00\n",
      "37   PUBorough_Brooklyn -4.372531e+00\n",
      "38    PUBorough_Unknown -4.355740e+00\n",
      "41        PUBorough_EWR  3.953106e+00\n",
      "36     PUBorough_Queens -1.745025e+00\n",
      "40        PUBorough_N/A  8.771515e-01\n",
      "19       hour_of_day_10 -3.942180e-01\n",
      "17       hour_of_day_11 -3.876403e-01\n",
      "13       hour_of_day_12 -3.833229e-01\n",
      "23        hour_of_day_7 -3.683635e-01\n",
      "14       hour_of_day_13 -3.647642e-01\n",
      "11       hour_of_day_14 -3.339801e-01\n",
      "16       hour_of_day_15 -3.286762e-01\n",
      "18        hour_of_day_9 -3.239464e-01\n",
      "6        hour_of_day_19 -3.192633e-01\n",
      "7        hour_of_day_18 -3.191906e-01\n",
      "25        hour_of_day_6 -3.095514e-01\n",
      "12       hour_of_day_17 -3.080025e-01\n",
      "27        hour_of_day_3 -3.037761e-01\n",
      "20        hour_of_day_8 -2.984289e-01\n",
      "21       hour_of_day_16 -2.976532e-01\n",
      "8        hour_of_day_20 -2.742816e-01\n",
      "26        hour_of_day_2 -2.730289e-01\n",
      "28        hour_of_day_4 -2.508241e-01\n",
      "24        hour_of_day_1 -2.354224e-01\n",
      "9        hour_of_day_21 -2.223241e-01\n",
      "3     passenger_count_1  2.021034e-01\n",
      "22        hour_of_day_0 -1.963926e-01\n",
      "5    passenger_count_5_  1.925558e-01\n",
      "15       hour_of_day_23 -1.868523e-01\n",
      "10       hour_of_day_22 -1.852376e-01\n",
      "4   passenger_count_2_4  1.348384e-01\n",
      "31        day_of_week_5  1.139911e-01\n",
      "32        day_of_week_4  1.106081e-01\n",
      "29        day_of_week_7 -9.015256e-02\n",
      "0               weekend -7.131415e-02\n",
      "33        day_of_week_3  6.607244e-02\n",
      "30        day_of_week_6  4.064937e-02\n",
      "34        day_of_week_1 -2.474859e-02\n",
      "2           fare_amount  8.035209e-04\n",
      "1         trip_distance  3.434427e-08"
     ]
    }
   ],
   "source": [
    "# Extract the coefficients and feature names\n",
    "linear_model = pipeline_model.stages[-1]\n",
    "coefficients = linear_model.coefficients\n",
    "feature_names = ['weekend', 'trip_distance', 'fare_amount'] + \\\n",
    "                  passenger_count_features + \\\n",
    "                  hour_features + \\\n",
    "                  day_features + \\\n",
    "                  PUBorough_features\n",
    "\n",
    "# Display the baseline category for one-hot encoded features\n",
    "baselines = {\n",
    "    \"day_baseline\": day_baseline,\n",
    "    \"hour_baseline\": hour_baseline,\n",
    "    \"PUBorough_baseline\": PUBorough_baseline,\n",
    "    \"passenger_count_baseline\": passenger_count_baseline\n",
    "}\n",
    "\n",
    "# Print the variable names along with their values\n",
    "for name, value in baselines.items():\n",
    "    print(f\"{name}: {value}\")\n",
    "    \n",
    "feature_importance = pd.DataFrame(list(zip(feature_names, coefficients)), columns=[\"Feature\", \"Coefficient\"])\n",
    "# Sort by the absolute value of the coefficient in descending order\n",
    "feature_importance_sorted = feature_importance.reindex(feature_importance.Coefficient.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Display the sorted feature importance\n",
    "print(feature_importance_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2c - Describe What Happens Under the Hood in Spark\n",
    "\n",
    "When specifying a series of transformations in a Spark pipeline, the DataFrame is not immediately processed. Instead, Spark uses lazy evaluation to build a logical plan outlining the transformations. This plan is optimized but not executed until an action like fit, transform, or collect is called. Upon triggering an action, Spark's Catalyst optimizer converts the logical plan into a physical plan, which is then executed across the cluster.\n",
    "\n",
    "This approach allows Spark to optimize the execution plan, ensuring efficient resource use. In contrast, Dask also employs lazy evaluation, building a task graph that is executed only when compute is called. Both systems delay execution for optimization, but Spark uses Catalyst for query optimization, while Dask relies on its task scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 - Finding Optimal Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run Q3, I increased the size of my EMR cluster to 8 m5.xlarge EC2 instances (1 primary node and 7 core nodes) to speed up the whole process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True"
     ]
    }
   ],
   "source": [
    "# Use the subset of the data for a 5-fold cross-validated grid search\n",
    "sample_data = data.sample(fraction=0.001, seed=42)\n",
    "train, test = sample_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Persist data in memory to speed up I/O during training/testing\n",
    "train.persist()\n",
    "test.persist()\n",
    "\n",
    "# confirm they're cached\n",
    "print(train.is_cached, test.is_cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+--------------------------------------------------------+\n",
      "|prediction        |tip_amount|features                                                |\n",
      "+------------------+----------+--------------------------------------------------------+\n",
      "|12.698637238215763|0.0       |(42,[2,3,15,31,41],[2.5,1.0,1.0,1.0,1.0])               |\n",
      "|6.94784247622159  |10.8      |(42,[0,1,2,3,16,34,35],[1.0,15.6,61.5,1.0,1.0,1.0,1.0]) |\n",
      "|8.226841491489846 |17.65     |(42,[0,1,2,5,14,29,35],[1.0,19.57,70.5,1.0,1.0,1.0,1.0])|\n",
      "|7.948019542653354 |16.0      |(42,[1,2,4,16,31,35],[17.8,70.0,1.0,1.0,1.0,1.0])       |\n",
      "|8.868740911395433 |18.0      |(42,[1,2,3,20,35],[20.6,75.5,1.0,1.0,1.0])              |\n",
      "+------------------+----------+--------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data: 1.967958258509648"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid using the specified ranges\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, np.arange(0, .1, .01))\n",
    "             .addGrid(lr.elasticNetParam, [0, 1])\n",
    "             .build())\n",
    "\n",
    "# Create the evaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"tip_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Create the CrossValidator\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=5) \n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cv_model = crossval.fit(train)\n",
    "\n",
    "# Make predictions on the test data and show the prediction\n",
    "predictions = cv_model.transform(test)\n",
    "predictions.select(\"prediction\", \"tip_amount\", \"features\").show(5, truncate=False)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regParam: 0.09\n",
      "Best elasticNetParam: 0.0"
     ]
    }
   ],
   "source": [
    "# Get the best model's parameters\n",
    "best_model = cv_model.bestModel\n",
    "print(f\"Best regParam: {best_model.stages[-1]._java_obj.getRegParam()}\")\n",
    "print(f\"Best elasticNetParam: {best_model.stages[-1]._java_obj.getElasticNetParam()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_baseline: day_of_week_2\n",
      "hour_baseline: hour_of_day_5\n",
      "PUBorough_baseline: PUBorough_Staten Island\n",
      "passenger_count_baseline: passenger_count_NA\n",
      "                Feature  Coefficient\n",
      "41        PUBorough_EWR    12.148250\n",
      "40        PUBorough_N/A     1.599610\n",
      "28        hour_of_day_4    -0.276413\n",
      "27        hour_of_day_3    -0.189775\n",
      "1         trip_distance     0.174381\n",
      "6        hour_of_day_19     0.141296\n",
      "10       hour_of_day_22     0.138313\n",
      "8        hour_of_day_20     0.132826\n",
      "7        hour_of_day_18     0.104940\n",
      "9        hour_of_day_21     0.102066\n",
      "19       hour_of_day_10     0.093880\n",
      "13       hour_of_day_12     0.089109\n",
      "25        hour_of_day_6    -0.080138\n",
      "29        day_of_week_7    -0.072869\n",
      "38    PUBorough_Unknown     0.070633\n",
      "0               weekend    -0.070324\n",
      "32        day_of_week_4     0.066281\n",
      "33        day_of_week_3     0.066075\n",
      "2           fare_amount     0.065893\n",
      "31        day_of_week_5     0.062111\n",
      "26        hour_of_day_2    -0.061890\n",
      "3     passenger_count_1     0.059450\n",
      "4   passenger_count_2_4    -0.058947\n",
      "18        hour_of_day_9     0.054037\n",
      "22        hour_of_day_0     0.044474\n",
      "34        day_of_week_1    -0.042413\n",
      "11       hour_of_day_14    -0.042378\n",
      "5    passenger_count_5_     0.038305\n",
      "39      PUBorough_Bronx    -0.034666\n",
      "23        hour_of_day_7     0.032887\n",
      "30        day_of_week_6     0.029292\n",
      "35  PUBorough_Manhattan    -0.027108\n",
      "16       hour_of_day_15    -0.024125\n",
      "14       hour_of_day_13     0.021148\n",
      "12       hour_of_day_17     0.018060\n",
      "15       hour_of_day_23    -0.015529\n",
      "17       hour_of_day_11    -0.010641\n",
      "20        hour_of_day_8    -0.010366\n",
      "36     PUBorough_Queens    -0.007581\n",
      "24        hour_of_day_1    -0.005971\n",
      "37   PUBorough_Brooklyn     0.005121\n",
      "21       hour_of_day_16    -0.000813"
     ]
    }
   ],
   "source": [
    "# Extract the coefficients and feature names\n",
    "coefficients = best_model.stages[-1].coefficients\n",
    "feature_names = ['weekend', 'trip_distance', 'fare_amount'] + \\\n",
    "                  passenger_count_features + \\\n",
    "                  hour_features + \\\n",
    "                  day_features + \\\n",
    "                  PUBorough_features\n",
    "\n",
    "# Display the baseline category for one-hot encoded features\n",
    "baselines = {\n",
    "    \"day_baseline\": day_baseline,\n",
    "    \"hour_baseline\": hour_baseline,\n",
    "    \"PUBorough_baseline\": PUBorough_baseline,\n",
    "    \"passenger_count_baseline\": passenger_count_baseline\n",
    "}\n",
    "for name, value in baselines.items():\n",
    "    print(f\"{name}: {value}\")\n",
    "\n",
    "# Display feature importance in descending order (of absolute value)\n",
    "feature_importance = pd.DataFrame(list(zip(feature_names, coefficients)), columns=[\"Feature\", \"Coefficient\"])\n",
    "feature_importance_sorted = feature_importance.reindex(feature_importance.Coefficient.abs().sort_values(ascending=False).index)\n",
    "print(feature_importance_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model evaluation shows a Root Mean Squared Error (RMSE) of 1.967, indicating that predictions are, on average, about 1.967 units away from actual tip amounts. The model uses a regularization parameter (regParam) of 0.09 and an elastic net parameter (elasticNetParam) of 0.0, emphasizing L2 regularization.\n",
    "\n",
    "Key predictors of tip amounts include pickup location and time of day. Trips from Newark (EWR) significantly increase tips, while early morning hours and weekends tend to decrease them. We can tell that hour_of_day and PUBorough might be the most relevant features for predicting tip amount because many of their one-hot encoded features have high coefficients among all features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
